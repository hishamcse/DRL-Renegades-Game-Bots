{"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"accelerator":"GPU","gpuClass":"standard","kaggle":{"accelerator":"none","dataSources":[{"sourceId":183371681,"sourceType":"kernelVersion"}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Unit 3: Deep Q-Learning with Atari Games üëæ using RL Baselines3 Zoo\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/thumbnail.jpg\" alt=\"Unit 3 Thumbnail\">\n\nIn this notebook, **you'll train a Deep Q-Learning agent** playing Space Invaders using [RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo), a training framework based on [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/) that provides scripts for training, evaluating agents, tuning hyperparameters, plotting results and recording videos.\n\nWe're using the [RL-Baselines-3 Zoo integration, a vanilla version of Deep Q-Learning](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html) with no extensions such as Double-DQN, Dueling-DQN, and Prioritized Experience Replay.\n\n‚¨áÔ∏è Here is an example of what **you will achieve** ‚¨áÔ∏è","metadata":{"id":"k7xBVPzoXxOg"}},{"cell_type":"code","source":"%%html\n<video controls autoplay><source src=\"https://huggingface.co/ThomasSimonini/ppo-SpaceInvadersNoFrameskip-v4/resolve/main/replay.mp4\" type=\"video/mp4\"></video>","metadata":{"id":"J9S713biXntc","execution":{"iopub.status.busy":"2024-06-13T20:07:33.938816Z","iopub.execute_input":"2024-06-13T20:07:33.939154Z","iopub.status.idle":"2024-06-13T20:07:33.946327Z","shell.execute_reply.started":"2024-06-13T20:07:33.939125Z","shell.execute_reply":"2024-06-13T20:07:33.945490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### üéÆ Environments:\n\n- [SpacesInvadersNoFrameskip-v4](https://gymnasium.farama.org/environments/atari/space_invaders/)\n\nYou can see the difference between Space Invaders versions here üëâ https://gymnasium.farama.org/environments/atari/space_invaders/#variants\n\n### üìö RL-Library:\n\n- [RL-Baselines3-Zoo](https://github.com/DLR-RM/rl-baselines3-zoo)","metadata":{"id":"ykJiGevCMVc5"}},{"cell_type":"markdown","source":"## Objectives of this notebook üèÜ\nAt the end of the notebook, you will:\n- Be able to understand deeper **how RL Baselines3 Zoo works**.\n- Be able to **push your trained agent and the code to the Hub** with a nice video replay and an evaluation score üî•.\n\n\n","metadata":{"id":"wciHGjrFYz9m"}},{"cell_type":"markdown","source":"## This notebook is from Deep Reinforcement Learning Course\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\"/>","metadata":{"id":"TsnP0rjxMn1e"}},{"cell_type":"markdown","source":"In this free course, you will:\n\n- üìñ Study Deep Reinforcement Learning in **theory and practice**.\n- üßë‚Äçüíª Learn to **use famous Deep RL libraries** such as Stable Baselines3, RL Baselines3 Zoo, CleanRL and Sample Factory 2.0.\n- ü§ñ Train **agents in unique environments**\n\nAnd more check üìö the syllabus üëâ https://simoninithomas.github.io/deep-rl-course\n\nDon‚Äôt forget to **<a href=\"http://eepurl.com/ic5ZUD\">sign up to the course</a>** (we are collecting your email to be able to¬†**send you the links when each Unit is published and give you information about the challenges and updates).**\n\n\nThe best way to keep in touch is to join our discord server to exchange with the community and with us üëâüèª https://discord.gg/ydHrjt3WP5","metadata":{"id":"nw6fJHIAZd-J"}},{"cell_type":"markdown","source":"## Prerequisites üèóÔ∏è\nBefore diving into the notebook, you need to:\n\nüî≤ üìö **[Study Deep Q-Learning by reading Unit 3](https://huggingface.co/deep-rl-course/unit3/introduction)**  ü§ó","metadata":{"id":"0vgANIBBZg1p"}},{"cell_type":"markdown","source":"We're constantly trying to improve our tutorials, so **if you find some issues in this notebook**, please [open an issue on the Github Repo](https://github.com/huggingface/deep-rl-class/issues).","metadata":{"id":"7kszpGFaRVhq"}},{"cell_type":"markdown","source":"# Let's train a Deep Q-Learning agent playing Atari' Space Invaders üëæ and upload it to the Hub.\n\nWe strongly recommend students **to use Google Colab for the hands-on exercises instead of running them on their personal computers**.\n\nBy using Google Colab, **you can focus on learning and experimenting without worrying about the technical aspects of setting up your environments**.\n\nTo validate this hands-on for the certification process, you need to push your trained model to the Hub and **get a result of >= 200**.\n\nTo find your result, go to the leaderboard and find your model, **the result = mean_reward - std of reward**\n\nFor more information about the certification process, check this section üëâ https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process","metadata":{"id":"QR0jZtYreSI5"}},{"cell_type":"markdown","source":"## An advice üí°\nIt's better to run this colab in a copy on your Google Drive, so that **if it timeouts** you still have the saved notebook on your Google Drive and do not need to fill everything from scratch.\n\nTo do that you can either do `Ctrl + S` or `File > Save a copy in Google Drive.`\n\nAlso, we're going to **train it for 90 minutes with 1M timesteps**. By typing `!nvidia-smi` will tell you what GPU you're using.\n\nAnd if you want to train more such 10 million steps, this will take about 9 hours, potentially resulting in Colab timing out. In that case, I recommend running this on your local computer (or somewhere else). Just click on: `File>Download`.","metadata":{"id":"Nc8BnyVEc3Ys"}},{"cell_type":"markdown","source":"## Set the GPU üí™\n- To **accelerate the agent's training, we'll use a GPU**. To do that, go to `Runtime > Change Runtime type`\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg\" alt=\"GPU Step 1\">","metadata":{"id":"PU4FVzaoM6fC"}},{"cell_type":"markdown","source":"- `Hardware Accelerator > GPU`\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg\" alt=\"GPU Step 2\">","metadata":{"id":"KV0NyFdQM9ZG"}},{"cell_type":"markdown","source":"# Install RL-Baselines3 Zoo and its dependencies üìö\n\nIf you see `ERROR: pip's dependency resolver does not currently take into account all the packages that are installed.` **this is normal and it's not a critical error** there's a conflict of version. But the packages we need are installed.","metadata":{"id":"wS_cVefO-aYg"}},{"cell_type":"code","source":"# For now we install this update of RL-Baselines3 Zoo\n!pip install git+https://github.com/DLR-RM/rl-baselines3-zoo@update/hf","metadata":{"id":"hLTwHqIWdnPb","execution":{"iopub.status.busy":"2024-06-14T04:40:46.844029Z","iopub.execute_input":"2024-06-14T04:40:46.844437Z","iopub.status.idle":"2024-06-14T04:42:24.353869Z","shell.execute_reply.started":"2024-06-14T04:40:46.844404Z","shell.execute_reply":"2024-06-14T04:42:24.351880Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/DLR-RM/rl-baselines3-zoo@update/hf\n  Cloning https://github.com/DLR-RM/rl-baselines3-zoo (to revision update/hf) to /tmp/pip-req-build-448nyfmu\n  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/rl-baselines3-zoo /tmp/pip-req-build-448nyfmu\n  Running command git checkout -b update/hf --track origin/update/hf\n  Switched to a new branch 'update/hf'\n  Branch 'update/hf' set up to track remote branch 'update/hf' from 'origin'.\n  Resolved https://github.com/DLR-RM/rl-baselines3-zoo to commit 7dcbff7e74e7a12c052452181ff353a4dbed313a\n  Running command git submodule update --init --recursive -q\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting sb3-contrib>=2.0.0a9 (from rl_zoo3==2.0.0a9)\n  Downloading sb3_contrib-2.3.0-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: gym==0.26.2 in /opt/conda/lib/python3.10/site-packages (from rl_zoo3==2.0.0a9) (0.26.2)\nCollecting huggingface-sb3>=2.2.1 (from rl_zoo3==2.0.0a9)\n  Downloading huggingface_sb3-3.0-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from rl_zoo3==2.0.0a9) (4.66.4)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from rl_zoo3==2.0.0a9) (13.7.0)\nRequirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (from rl_zoo3==2.0.0a9) (3.6.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from rl_zoo3==2.0.0a9) (6.0.1)\nCollecting pytablewriter~=0.64 (from rl_zoo3==2.0.0a9)\n  Downloading pytablewriter-0.64.2-py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from gym==0.26.2->rl_zoo3==2.0.0a9) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym==0.26.2->rl_zoo3==2.0.0a9) (2.2.1)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym==0.26.2->rl_zoo3==2.0.0a9) (0.0.8)\nRequirement already satisfied: huggingface-hub~=0.8 in /opt/conda/lib/python3.10/site-packages (from huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (0.23.2)\nRequirement already satisfied: wasabi in /opt/conda/lib/python3.10/site-packages (from huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (1.1.3)\nRequirement already satisfied: setuptools>=38.3.0 in /opt/conda/lib/python3.10/site-packages (from pytablewriter~=0.64->rl_zoo3==2.0.0a9) (69.0.3)\nCollecting DataProperty<2,>=0.55.0 (from pytablewriter~=0.64->rl_zoo3==2.0.0a9)\n  Downloading DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\nCollecting mbstrdecoder<2,>=1.0.0 (from pytablewriter~=0.64->rl_zoo3==2.0.0a9)\n  Downloading mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\nCollecting pathvalidate<3,>=2.3.0 (from pytablewriter~=0.64->rl_zoo3==2.0.0a9)\n  Downloading pathvalidate-2.5.2-py3-none-any.whl.metadata (11 kB)\nCollecting tabledata<2,>=1.3.0 (from pytablewriter~=0.64->rl_zoo3==2.0.0a9)\n  Downloading tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\nCollecting tcolorpy<1,>=0.0.5 (from pytablewriter~=0.64->rl_zoo3==2.0.0a9)\n  Downloading tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\nCollecting typepy<2,>=1.2.0 (from typepy[datetime]<2,>=1.2.0->pytablewriter~=0.64->rl_zoo3==2.0.0a9)\n  Downloading typepy-1.3.2-py3-none-any.whl.metadata (9.3 kB)\nCollecting stable-baselines3<3.0,>=2.3.0 (from sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9)\n  Downloading stable_baselines3-2.3.2-py3-none-any.whl.metadata (5.1 kB)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna->rl_zoo3==2.0.0a9) (1.13.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna->rl_zoo3==2.0.0a9) (6.8.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna->rl_zoo3==2.0.0a9) (21.3)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna->rl_zoo3==2.0.0a9) (2.0.25)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->rl_zoo3==2.0.0a9) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->rl_zoo3==2.0.0a9) (2.17.2)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->rl_zoo3==2.0.0a9) (1.3.5)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->rl_zoo3==2.0.0a9) (4.9.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub~=0.8->huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub~=0.8->huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (2024.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub~=0.8->huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (2.32.3)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->rl_zoo3==2.0.0a9) (0.1.2)\nCollecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter~=0.64->rl_zoo3==2.0.0a9)\n  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna->rl_zoo3==2.0.0a9) (3.1.1)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna->rl_zoo3==2.0.0a9) (3.0.3)\nRequirement already satisfied: gymnasium<0.30,>=0.28.1 in /opt/conda/lib/python3.10/site-packages (from stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (0.29.0)\nRequirement already satisfied: torch>=1.13 in /opt/conda/lib/python3.10/site-packages (from stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (2.1.2+cpu)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (2.2.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (3.7.5)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.2.0->pytablewriter~=0.64->rl_zoo3==2.0.0a9) (2.9.0.post0)\nRequirement already satisfied: pytz>=2018.9 in /opt/conda/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.2.0->pytablewriter~=0.64->rl_zoo3==2.0.0a9) (2023.3.post1)\nRequirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (0.0.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.0->typepy[datetime]<2,>=1.2.0->pytablewriter~=0.64->rl_zoo3==2.0.0a9) (1.16.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (3.1.2)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna->rl_zoo3==2.0.0a9) (2.1.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (9.5.0)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub~=0.8->huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub~=0.8->huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub~=0.8->huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub~=0.8->huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (1.3.0)\nDownloading huggingface_sb3-3.0-py3-none-any.whl (9.7 kB)\nDownloading pytablewriter-0.64.2-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sb3_contrib-2.3.0-py3-none-any.whl (80 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\nDownloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\nDownloading pathvalidate-2.5.2-py3-none-any.whl (20 kB)\nDownloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tabledata-1.3.3-py3-none-any.whl (11 kB)\nDownloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\nDownloading typepy-1.3.2-py3-none-any.whl (31 kB)\nDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rl_zoo3\n  Building wheel for rl_zoo3 (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rl_zoo3: filename=rl_zoo3-2.0.0a9-py3-none-any.whl size=76402 sha256=aeefb2840b6f86ff8ccc54001c0cdc57f0a8b63f1b5344a8b52e7e592e953a27\n  Stored in directory: /tmp/pip-ephem-wheel-cache-e1oqlqa6/wheels/fc/36/d5/2ef574649d85327de098075c8523da50be2612f3e5807261f7\nSuccessfully built rl_zoo3\nInstalling collected packages: tcolorpy, pathvalidate, chardet, mbstrdecoder, typepy, stable-baselines3, huggingface-sb3, sb3-contrib, DataProperty, tabledata, pytablewriter, rl_zoo3\n  Attempting uninstall: stable-baselines3\n    Found existing installation: stable-baselines3 2.1.0\n    Uninstalling stable-baselines3-2.1.0:\n      Successfully uninstalled stable-baselines3-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.14.11 requires stable-baselines3==2.1.0, but you have stable-baselines3 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed DataProperty-1.0.1 chardet-5.2.0 huggingface-sb3-3.0 mbstrdecoder-1.1.3 pathvalidate-2.5.2 pytablewriter-0.64.2 rl_zoo3-2.0.0a9 sb3-contrib-2.3.0 stable-baselines3-2.3.2 tabledata-1.3.3 tcolorpy-0.1.6 typepy-1.3.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"IF AND ONLY IF THE VERSION ABOVE DOES NOT EXIST ANYMORE. UNCOMMENT AND INSTALL THE ONE BELOW","metadata":{"id":"p0xe2sJHdtHy"}},{"cell_type":"code","source":"#!pip install rl_zoo3==2.0.0a9","metadata":{"id":"N0d6wy-F-f39"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt-get install -y swig cmake ffmpeg","metadata":{"id":"8_MllY6Om1eI","execution":{"iopub.status.busy":"2024-06-14T04:42:24.357474Z","iopub.execute_input":"2024-06-14T04:42:24.357938Z","iopub.status.idle":"2024-06-14T04:42:33.308438Z","shell.execute_reply.started":"2024-06-14T04:42:24.357895Z","shell.execute_reply":"2024-06-14T04:42:33.307137Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\ncmake is already the newest version (3.16.3-1ubuntu1.20.04.1).\nffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\nThe following additional packages will be installed:\n  swig4.0\nSuggested packages:\n  swig-doc swig-examples swig4.0-examples swig4.0-doc\nThe following NEW packages will be installed:\n  swig swig4.0\n0 upgraded, 2 newly installed, 0 to remove and 64 not upgraded.\nNeed to get 1086 kB of archives.\nAfter this operation, 5413 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 swig4.0 amd64 4.0.1-5build1 [1081 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 swig all 4.0.1-5build1 [5528 B]\nFetched 1086 kB in 1s (792 kB/s)\nSelecting previously unselected package swig4.0.\n(Reading database ... 110195 files and directories currently installed.)\nPreparing to unpack .../swig4.0_4.0.1-5build1_amd64.deb ...\nUnpacking swig4.0 (4.0.1-5build1) ...\nSelecting previously unselected package swig.\nPreparing to unpack .../swig_4.0.1-5build1_all.deb ...\nUnpacking swig (4.0.1-5build1) ...\nSetting up swig4.0 (4.0.1-5build1) ...\nSetting up swig (4.0.1-5build1) ...\nProcessing triggers for man-db (2.9.1-1) ...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"To be able to use Atari games in Gymnasium we need to install atari package. And accept-rom-license to download the rom files (games files).","metadata":{"id":"4S9mJiKg6SqC"}},{"cell_type":"code","source":"!pip install gymnasium[atari]\n!pip install gymnasium[accept-rom-license]","metadata":{"id":"NsRP-lX1_2fC","execution":{"iopub.status.busy":"2024-06-14T04:42:33.310454Z","iopub.execute_input":"2024-06-14T04:42:33.310943Z","iopub.status.idle":"2024-06-14T04:43:23.672645Z","shell.execute_reply.started":"2024-06-14T04:42:33.310894Z","shell.execute_reply":"2024-06-14T04:43:23.671404Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gymnasium[atari] in /opt/conda/lib/python3.10/site-packages (0.29.0)\nRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium[atari]) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium[atari]) (2.2.1)\nRequirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium[atari]) (4.9.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from gymnasium[atari]) (0.0.4)\nCollecting shimmy<1.0,>=0.1.0 (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari])\n  Downloading Shimmy-0.2.1-py3-none-any.whl.metadata (2.3 kB)\nCollecting ale-py~=0.8.1 (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari])\n  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]) (6.1.1)\nDownloading Shimmy-0.2.1-py3-none-any.whl (25 kB)\nDownloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ale-py, shimmy\n  Attempting uninstall: shimmy\n    Found existing installation: Shimmy 1.3.0\n    Uninstalling Shimmy-1.3.0:\n      Successfully uninstalled Shimmy-1.3.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.14.11 requires shimmy>=1.2.1, but you have shimmy 0.2.1 which is incompatible.\nkaggle-environments 1.14.11 requires stable-baselines3==2.1.0, but you have stable-baselines3 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ale-py-0.8.1 shimmy-0.2.1\nRequirement already satisfied: gymnasium[accept-rom-license] in /opt/conda/lib/python3.10/site-packages (0.29.0)\nRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium[accept-rom-license]) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium[accept-rom-license]) (2.2.1)\nRequirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium[accept-rom-license]) (4.9.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from gymnasium[accept-rom-license]) (0.0.4)\nCollecting autorom~=0.4.2 (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license])\n  Downloading AutoROM-0.4.2-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (8.1.7)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (4.66.4)\nCollecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license])\n  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (2024.2.2)\nDownloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\nBuilding wheels for collected packages: AutoROM.accept-rom-license\n  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446659 sha256=454759fbe01f7fd45a0ba1277c94be8ada9c293ec4a5934e075bb55c3c476c55\n  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\nSuccessfully built AutoROM.accept-rom-license\nInstalling collected packages: AutoROM.accept-rom-license, autorom\nSuccessfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.4.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Create a virtual display üîΩ\n\nDuring the notebook, we'll need to generate a replay video. To do so, with colab, **we need to have a virtual screen to be able to render the environment** (and thus record the frames).\n\nHence the following cell will install the librairies and create and run a virtual screen üñ•","metadata":{"id":"bTpYcVZVMzUI"}},{"cell_type":"code","source":"# import os\n# os.kill(os.getpid(), 9)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:22:09.103271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%capture\n# !apt install python-opengl\n# !apt install xvfb\n# !pip3 install pyvirtualdisplay","metadata":{"id":"jV6wjQ7Be7p5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sudo apt-get update\n!sudo apt-get install -y python3-opengl\n!apt install ffmpeg\n!apt install xvfb\n!pip3 install pyvirtualdisplay\n\n!pip install moviepy==1.0.3","metadata":{"execution":{"iopub.status.busy":"2024-06-14T04:43:23.675295Z","iopub.execute_input":"2024-06-14T04:43:23.675675Z","iopub.status.idle":"2024-06-14T04:44:35.366371Z","shell.execute_reply.started":"2024-06-14T04:43:23.675638Z","shell.execute_reply":"2024-06-14T04:44:35.364815Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [128 kB]\nHit:2 http://archive.ubuntu.com/ubuntu focal InRelease                         \nGet:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [128 kB]        \nHit:4 https://packages.cloud.google.com/apt gcsfuse-focal InRelease            \nGet:5 https://packages.cloud.google.com/apt cloud-sdk InRelease [1616 B]       \nHit:6 http://archive.ubuntu.com/ubuntu focal-backports InRelease               \nGet:7 https://packages.cloud.google.com/apt cloud-sdk/main all Packages [1459 kB]\nGet:8 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [3651 kB]\nGet:9 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [3035 kB]\nGet:10 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [4182 kB]\nGet:11 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [3710 kB]\nGet:12 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1213 kB]\nGet:13 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1511 kB]\nGet:14 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [3800 kB]\nFetched 22.8 MB in 2s (9533 kB/s)                            \nReading package lists... Done\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  freeglut3 libglu1-mesa\nSuggested packages:\n  python3-numpy libgle3\nThe following NEW packages will be installed:\n  freeglut3 libglu1-mesa python3-opengl\n0 upgraded, 3 newly installed, 0 to remove and 70 not upgraded.\nNeed to get 728 kB of archives.\nAfter this operation, 6216 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libglu1-mesa amd64 9.0.1-1build1 [168 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-opengl all 3.1.0+dfsg-2build1 [486 kB]\nFetched 728 kB in 1s (1179 kB/s)      \nSelecting previously unselected package freeglut3:amd64.\n(Reading database ... 110946 files and directories currently installed.)\nPreparing to unpack .../freeglut3_2.8.1-3_amd64.deb ...\nUnpacking freeglut3:amd64 (2.8.1-3) ...\nSelecting previously unselected package libglu1-mesa:amd64.\nPreparing to unpack .../libglu1-mesa_9.0.1-1build1_amd64.deb ...\nUnpacking libglu1-mesa:amd64 (9.0.1-1build1) ...\nSelecting previously unselected package python3-opengl.\nPreparing to unpack .../python3-opengl_3.1.0+dfsg-2build1_all.deb ...\nUnpacking python3-opengl (3.1.0+dfsg-2build1) ...\nSetting up freeglut3:amd64 (2.8.1-3) ...\nSetting up libglu1-mesa:amd64 (9.0.1-1build1) ...\nSetting up python3-opengl (3.1.0+dfsg-2build1) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.14) ...\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n0 upgraded, 0 newly installed, 0 to remove and 70 not upgraded.\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nxvfb is already the newest version (2:1.20.13-1ubuntu1~20.04.17).\n0 upgraded, 0 newly installed, 0 to remove and 70 not upgraded.\nCollecting pyvirtualdisplay\n  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\nDownloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\nInstalling collected packages: pyvirtualdisplay\nSuccessfully installed pyvirtualdisplay-3.0\nCollecting moviepy==1.0.3\n  Downloading moviepy-1.0.3.tar.gz (388 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting decorator<5.0,>=4.0.2 (from moviepy==1.0.3)\n  Downloading decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy==1.0.3) (4.66.4)\nRequirement already satisfied: requests<3.0,>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from moviepy==1.0.3) (2.32.3)\nCollecting proglog<=1.0.0 (from moviepy==1.0.3)\n  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy==1.0.3) (1.26.4)\nRequirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy==1.0.3) (2.33.1)\nCollecting imageio_ffmpeg>=0.2.0 (from moviepy==1.0.3)\n  Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy==1.0.3) (9.5.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy==1.0.3) (69.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (2024.2.2)\nDownloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\nDownloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\nBuilding wheels for collected packages: moviepy\n  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110720 sha256=e9b42d74ec1843a30e2ae57490b5eef5f175ee6fb94bd0200e0d04549945ee6e\n  Stored in directory: /root/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\nSuccessfully built moviepy\nInstalling collected packages: proglog, imageio_ffmpeg, decorator, moviepy\n  Attempting uninstall: decorator\n    Found existing installation: decorator 5.1.1\n    Uninstalling decorator-5.1.1:\n      Successfully uninstalled decorator-5.1.1\nSuccessfully installed decorator-4.4.2 imageio_ffmpeg-0.5.1 moviepy-1.0.3 proglog-0.1.10\n","output_type":"stream"}]},{"cell_type":"code","source":"# Virtual display\nfrom pyvirtualdisplay import Display\n\nvirtual_display = Display(visible=0, size=(1400, 900))\nvirtual_display.start()","metadata":{"id":"BE5JWP5rQIKf","execution":{"iopub.status.busy":"2024-06-14T04:44:35.368390Z","iopub.execute_input":"2024-06-14T04:44:35.368874Z","iopub.status.idle":"2024-06-14T04:44:35.802379Z","shell.execute_reply.started":"2024-06-14T04:44:35.368823Z","shell.execute_reply":"2024-06-14T04:44:35.801247Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<pyvirtualdisplay.display.Display at 0x7e3a2d279150>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Train our Deep Q-Learning Agent to Play Space Invaders üëæ\n\nTo train an agent with RL-Baselines3-Zoo, we just need to do two things:\n\n1. Create a hyperparameter config file that will contain our training hyperparameters called `dqn.yml`.\n\nThis is a template example:\n\n```\nSpaceInvadersNoFrameskip-v4:\n  env_wrapper:\n    - stable_baselines3.common.atari_wrappers.AtariWrapper\n  frame_stack: 4\n  policy: 'CnnPolicy'\n  n_timesteps: !!float 1e6\n  buffer_size: 100000\n  learning_rate: !!float 1e-4\n  batch_size: 32\n  learning_starts: 100000\n  target_update_interval: 1000\n  train_freq: 4\n  gradient_steps: 1\n  exploration_fraction: 0.1\n  exploration_final_eps: 0.01\n  # If True, you need to deactivate handle_timeout_termination\n  # in the replay_buffer_kwargs\n  optimize_memory_usage: False\n```","metadata":{"id":"5iPgzluo9z-u"}},{"cell_type":"markdown","source":"Here we see that:\n- We use the `Atari Wrapper` that preprocess the input (Frame reduction ,grayscale, stack 4 frames)\n- We use `CnnPolicy`, since we use Convolutional layers to process the frames\n- We train it for 10 million `n_timesteps`\n- Memory (Experience Replay) size is 100000, aka the amount of experience steps you saved to train again your agent with.\n\nüí° My advice is to **reduce the training timesteps to 1M,** which will take about 90 minutes on a P100. `!nvidia-smi` will tell you what GPU you're using. At 10 million steps, this will take about 9 hours, which could likely result in Colab timing out. I recommend running this on your local computer (or somewhere else). Just click on: `File>Download`.","metadata":{"id":"_VjblFSVDQOj"}},{"cell_type":"markdown","source":"In terms of hyperparameters optimization, my advice is to focus on these 3 hyperparameters:\n- `learning_rate`\n- `buffer_size (Experience Memory size)`\n- `batch_size`\n\nAs a good practice, you need to **check the documentation to understand what each hyperparameters does**: https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html#parameters\n\n","metadata":{"id":"5qTkbWrkECOJ"}},{"cell_type":"code","source":"%%writefile dqn.yml\nSpaceInvadersNoFrameskip-v4:\n  env_wrapper:\n    - stable_baselines3.common.atari_wrappers.AtariWrapper\n  frame_stack: 4\n  policy: 'CnnPolicy'\n  n_timesteps: !!float 2e6\n  buffer_size: 400000\n  learning_rate: !!float 1e-4\n  batch_size: 32\n  gamma: .99\n  learning_starts: 100000\n  target_update_interval: 5000\n  train_freq: 4\n  gradient_steps: 1\n  exploration_fraction: 0.1\n  exploration_final_eps: 0.01\n  # If True, you need to deactivate handle_timeout_termination\n  # in the replay_buffer_kwargs\n  optimize_memory_usage: False\n  normalize: False","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:26:40.584749Z","iopub.execute_input":"2024-06-13T20:26:40.585609Z","iopub.status.idle":"2024-06-13T20:26:40.592775Z","shell.execute_reply.started":"2024-06-13T20:26:40.585573Z","shell.execute_reply":"2024-06-13T20:26:40.591634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. We start the training and save the models on `logs` folder üìÅ\n\n- Define the algorithm after `--algo`, where we save the model after `-f` and where the hyperparameter config is after `-c`.","metadata":{"id":"Hn8bRTHvERRL"}},{"cell_type":"markdown","source":"#### Solution","metadata":{"id":"SeChoX-3SZfP"}},{"cell_type":"code","source":"!python -m rl_zoo3.train --algo dqn  --env SpaceInvadersNoFrameskip-v4 -f logs/ -c dqn.yml","metadata":{"id":"PuocgdokSab9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's evaluate our agent üëÄ\n- RL-Baselines3-Zoo provides `enjoy.py`, a python script to evaluate our agent. In most RL libraries, we call the evaluation script `enjoy.py`.\n- Let's evaluate it for 10000 timesteps üî•","metadata":{"id":"_dLomIiMKQaf"}},{"cell_type":"markdown","source":"#### Solution","metadata":{"id":"Q24K1tyWSj7t"}},{"cell_type":"code","source":"!python -m rl_zoo3.enjoy  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --no-render  --n-timesteps 10000  --folder logs/","metadata":{"id":"P_uSmwGRSk0z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Publish our trained model on the Hub üöÄ\nNow that we saw we got good results after the training, we can publish our trained model on the hub ü§ó with one line of code.\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit3/space-invaders-model.gif\" alt=\"Space Invaders model\">","metadata":{"id":"liBeTltiHJtr"}},{"cell_type":"markdown","source":"By using `rl_zoo3.push_to_hub` **you evaluate, record a replay, generate a model card of your agent and push it to the hub**.\n\nThis way:\n- You can **showcase our work** üî•\n- You can **visualize your agent playing** üëÄ\n- You can **share with the community an agent that others can use** üíæ\n- You can **access a leaderboard üèÜ to see how well your agent is performing compared to your classmates** üëâ  https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard","metadata":{"id":"ezbHS1q3HYVV"}},{"cell_type":"markdown","source":"To be able to share your model with the community there are three more steps to follow:\n\n1Ô∏è‚É£ (If it's not already done) create an account to HF ‚û° https://huggingface.co/join\n\n2Ô∏è‚É£ Sign in and then, you need to store your authentication token from the Hugging Face website.\n- Create a new token (https://huggingface.co/settings/tokens) **with write role**\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\">","metadata":{"id":"XMSeZRBiHk6X"}},{"cell_type":"markdown","source":"- Copy the token\n- Run the cell below and past the token","metadata":{"id":"9O6FI0F8HnzE"}},{"cell_type":"code","source":"from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\nnotebook_login()\n!git config --global credential.helper store","metadata":{"id":"Ppu9yePwHrZX","execution":{"iopub.status.busy":"2024-06-14T04:45:42.268517Z","iopub.execute_input":"2024-06-14T04:45:42.268982Z","iopub.status.idle":"2024-06-14T04:45:43.750139Z","shell.execute_reply.started":"2024-06-14T04:45:42.268946Z","shell.execute_reply":"2024-06-14T04:45:43.748400Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3bf706d69d3439a800328cf8f8fce9a"}},"metadata":{}}]},{"cell_type":"markdown","source":"If you don't want to use a Google Colab or a Jupyter Notebook, you need to use this command instead: `huggingface-cli login`","metadata":{"id":"2RVEdunPHs8B"}},{"cell_type":"markdown","source":"3Ô∏è‚É£ We're now ready to push our trained agent to the ü§ó Hub üî•","metadata":{"id":"dSLwdmvhHvjw"}},{"cell_type":"markdown","source":"Let's run push_to_hub.py file to upload our trained agent to the Hub.\n\n`--repo-name `: The name of the repo\n\n`-orga`: Your Hugging Face username\n\n`-f`: Where the trained model folder is (in our case `logs`)\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit3/select-id.png\" alt=\"Select Id\">","metadata":{"id":"PW436XnhHw1H"}},{"cell_type":"markdown","source":"#### Solution","metadata":{"id":"otgpa0rhS9wR"}},{"cell_type":"code","source":"# !rm -rf /kaggle/working/hub/dqn-SpaceInvadersNoFrameskip-v4-final","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:29:40.647867Z","iopub.execute_input":"2024-06-14T05:29:40.648328Z","iopub.status.idle":"2024-06-14T05:29:41.742944Z","shell.execute_reply.started":"2024-06-14T05:29:40.648285Z","shell.execute_reply":"2024-06-14T05:29:41.741336Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import shutil\nsrc_path = r\"/kaggle/input/drl-huggingface-unit-3-sp-inv-pong-breakout-pacman/logs/dqn/SpaceInvadersNoFrameskip-v4_1/evaluations.npz\"\ndst_path = r\"/kaggle/working/logs/dqn/SpaceInvadersNoFrameskip-v4_1/evaluations.npz\"\nshutil.copy(src_path, dst_path)\nprint('Copied')","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:32:43.985751Z","iopub.execute_input":"2024-06-14T05:32:43.986202Z","iopub.status.idle":"2024-06-14T05:32:44.003699Z","shell.execute_reply.started":"2024-06-14T05:32:43.986167Z","shell.execute_reply":"2024-06-14T05:32:44.002239Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Copied\n","output_type":"stream"}]},{"cell_type":"code","source":"!python -m rl_zoo3.push_to_hub  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --repo-name dqn-SpaceInvadersNoFrameskip-v4  -orga hishamcse  -f logs/","metadata":{"id":"_HQNlAXuEhci","execution":{"iopub.status.busy":"2024-06-14T05:33:45.160488Z","iopub.execute_input":"2024-06-14T05:33:45.161010Z","iopub.status.idle":"2024-06-14T05:34:58.475590Z","shell.execute_reply.started":"2024-06-14T05:33:45.160958Z","shell.execute_reply":"2024-06-14T05:34:58.474031Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"2024-06-14 05:33:50.040985: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-14 05:33:50.041072: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-14 05:33:50.044044: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nLoading latest experiment, id=1\nLoading logs/dqn/SpaceInvadersNoFrameskip-v4_1/SpaceInvadersNoFrameskip-v4.zip\nA.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n[Powered by Stella]\nStacking 4 frames\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object learning_rate. Consider using `custom_objects` argument to replace this object.\nException: Can't get attribute '_function_setstate' on <module 'cloudpickle.cloudpickle' from '/opt/conda/lib/python3.10/site-packages/cloudpickle/cloudpickle.py'>\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\nException: Can't get attribute '_function_setstate' on <module 'cloudpickle.cloudpickle' from '/opt/conda/lib/python3.10/site-packages/cloudpickle/cloudpickle.py'>\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object exploration_schedule. Consider using `custom_objects` argument to replace this object.\nException: Can't get attribute '_function_setstate' on <module 'cloudpickle.cloudpickle' from '/opt/conda/lib/python3.10/site-packages/cloudpickle/cloudpickle.py'>\n  warnings.warn(\nWrapping the env in a VecTransposeImage.\nUploading to hishamcse/dqn-SpaceInvadersNoFrameskip-v4, make sure to have the rights\n\u001b[38;5;4m‚Ñπ This function will save, evaluate, generate a video of your agent,\ncreate a model card and push everything to the hub. It might take up to some\nminutes if video generation is activated. This is a work in progress: if you\nencounter a bug, please open an issue.\u001b[0m\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\nFor more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n  warnings.warn(warning_message, FutureWarning)\nCloning https://huggingface.co/hishamcse/dqn-SpaceInvadersNoFrameskip-v4 into local empty directory.\nSaving model to: hub/dqn-SpaceInvadersNoFrameskip-v4/dqn-SpaceInvadersNoFrameskip-v4\n/opt/conda/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:335: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n  logger.warn(\nSaving video to /tmp/tmp7rtc87vx/-step-0-to-step-1000.mp4\nMoviepy - Building video /tmp/tmp7rtc87vx/-step-0-to-step-1000.mp4.\nMoviepy - Writing video /tmp/tmp7rtc87vx/-step-0-to-step-1000.mp4\n\nMoviepy - Done !                                                                \nMoviepy - video ready /tmp/tmp7rtc87vx/-step-0-to-step-1000.mp4\nffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 31.100 / 56. 31.100\n  libavcodec     58. 54.100 / 58. 54.100\n  libavformat    58. 29.100 / 58. 29.100\n  libavdevice    58.  8.100 / 58.  8.100\n  libavfilter     7. 57.100 /  7. 57.100\n  libavresample   4.  0.  0 /  4.  0.  0\n  libswscale      5.  5.100 /  5.  5.100\n  libswresample   3.  5.100 /  3.  5.100\n  libpostproc    55.  5.100 / 55.  5.100\nInput #0, mov,mp4,m4a,3gp,3g2,mj2, from '/tmp/tmp7rtc87vx/-step-0-to-step-1000.mp4':\n  Metadata:\n    major_brand     : isom\n    minor_version   : 512\n    compatible_brands: isomiso2avc1mp41\n    encoder         : Lavf58.29.100\n  Duration: 00:00:33.40, start: 0.000000, bitrate: 59 kb/s\n    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 160x210, 56 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n    Metadata:\n      handler_name    : VideoHandler\nStream mapping:\n  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\nPress [q] to stop, [?] for help\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mprofile High, level 1.2\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0m264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=6 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\nOutput #0, mp4, to 'hub/dqn-SpaceInvadersNoFrameskip-v4/replay.mp4':\n  Metadata:\n    major_brand     : isom\n    minor_version   : 512\n    compatible_brands: isomiso2avc1mp41\n    encoder         : Lavf58.29.100\n    Stream #0:0(und): Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 160x210, q=-1--1, 30 fps, 15360 tbn, 30 tbc (default)\n    Metadata:\n      handler_name    : VideoHandler\n      encoder         : Lavc58.54.100 libx264\n    Side data:\n      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\nframe= 1002 fps=0.0 q=-1.0 Lsize=     233kB time=00:00:33.30 bitrate=  57.4kbits/s speed=48.3x    \nvideo:223kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 4.859728%\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mframe I:5     Avg QP:14.79  size:  3604\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mframe P:503   Avg QP:23.09  size:   361\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mframe B:494   Avg QP:29.17  size:    56\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mconsecutive B-frames: 28.2% 14.6% 10.5% 46.7%\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mmb I  I16..4: 40.7% 15.4% 43.9%\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mmb P  I16..4:  0.5%  0.9%  0.9%  P16..4:  7.3%  3.2%  1.9%  0.0%  0.0%    skip:85.3%\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mmb B  I16..4:  0.2%  0.1%  0.1%  B16..8: 10.6%  1.1%  0.1%  direct: 0.2%  skip:87.7%  L0:51.5% L1:48.1% BI: 0.4%\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0m8x8 transform intra:32.1% inter:5.2%\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mcoded y,uvDC,uvAC intra: 23.1% 40.0% 37.1% inter: 1.6% 2.1% 1.7%\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mi16 v,h,dc,p: 57% 36%  7%  0%\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 19%  6% 73%  1%  0%  0%  0%  0%  0%\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 33% 12% 41%  3%  1%  3%  2%  2%  1%\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mi8c dc,h,v,p: 53% 27% 19%  1%\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mref P L0: 74.9%  6.3%  9.3%  9.5%\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mref B L0: 84.5% 11.8%  3.6%\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mref B L1: 96.6%  3.4%\n\u001b[1;36m[libx264 @ 0x5b100d72ee40] \u001b[0mkb/s:54.43\n\u001b[38;5;4m‚Ñπ Pushing repo dqn-SpaceInvadersNoFrameskip-v4 to the Hugging Face\nHub\u001b[0m\nUpload file dqn-SpaceInvadersNoFrameskip-v4.zip:   0%| | 1.00/26.0M [00:00<?, ?B\nUpload file dqn-SpaceInvadersNoFrameskip-v4/pytorch_variables.pth:   0%| | 1.00/\u001b[A\n\nUpload file replay.mp4:   0%|                        | 1.00/233k [00:00<?, ?B/s]\u001b[A\u001b[A\n\n\nUpload file train_eval_metrics.zip:   0%|           | 1.00/63.1k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n\n\n\nUpload file dqn-SpaceInvadersNoFrameskip-v4/policy.pth:   0%| | 1.00/12.9M [00:0\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nUpload file dqn-SpaceInvadersNoFrameskip-v4/policy.optimizer.pth:   0%| | 1.00/1\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\nUpload file dqn-SpaceInvadersNoFrameskip-v4.zip:  59%|‚ñå| 15.3M/26.0M [00:02<00:0\u001b[A\u001b[A\u001b[A\u001b[ATo https://huggingface.co/hishamcse/dqn-SpaceInvadersNoFrameskip-v4\n   3669bc8..925e926  main -> main\n\nUpload file dqn-SpaceInvadersNoFrameskip-v4.zip: 100%|‚ñà| 26.0M/26.0M [00:03<00:0\n\nUpload file dqn-SpaceInvadersNoFrameskip-v4/pytorch_variables.pth: 100%|‚ñà| 864/8\u001b[A\nUpload file dqn-SpaceInvadersNoFrameskip-v4/pytorch_variables.pth: 100%|‚ñà| 864/8\u001b[A\n\n\nUpload file replay.mp4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 233k/233k [00:03<00:00, 5.32MB/s]\u001b[A\u001b[A\n\nUpload file replay.mp4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 233k/233k [00:03<00:00, 79.5kB/s]\u001b[A\u001b[A\n\n\n\nUpload file train_eval_metrics.zip: 100%|‚ñà‚ñà| 63.1k/63.1k [00:03<00:00, 5.32MB/s]\u001b[A\u001b[A\u001b[A\n\n\nUpload file train_eval_metrics.zip: 100%|‚ñà‚ñà| 63.1k/63.1k [00:03<00:00, 21.5kB/s]\u001b[A\u001b[A\u001b[A\n\n\n\n\nUpload file dqn-SpaceInvadersNoFrameskip-v4/policy.pth: 100%|‚ñà| 12.9M/12.9M [00:\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nUpload file dqn-SpaceInvadersNoFrameskip-v4/policy.optimizer.pth: 100%|‚ñà| 12.9M/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nUpload file dqn-SpaceInvadersNoFrameskip-v4/policy.optimizer.pth: 100%|‚ñà| 12.9M/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\u001b[38;5;4m‚Ñπ Your model is pushed to the hub. You can view your model here:\nhttps://huggingface.co/hishamcse/dqn-SpaceInvadersNoFrameskip-v4\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Congrats ü•≥ you've just trained and uploaded your first Deep Q-Learning agent using RL-Baselines-3 Zoo. The script above should have displayed a link to a model repository such as https://huggingface.co/ThomasSimonini/dqn-SpaceInvadersNoFrameskip-v4. When you go to this link, you can:\n\n- See a **video preview of your agent** at the right.\n- Click \"Files and versions\" to see all the files in the repository.\n- Click \"Use in stable-baselines3\" to get a code snippet that shows how to load the model.\n- A model card (`README.md` file) which gives a description of the model and the hyperparameters you used.\n\nUnder the hood, the Hub uses git-based repositories (don't worry if you don't know what git is), which means you can update the model with new versions as you experiment and improve your agent.\n\n**Compare the results of your agents with your classmates** using the [leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard) üèÜ","metadata":{"id":"ff89kd2HL1_s"}},{"cell_type":"markdown","source":"## Load a powerful trained model üî•\n- The Stable-Baselines3 team uploaded **more than 150 trained Deep Reinforcement Learning agents on the Hub**.\n\nYou can find them here: üëâ https://huggingface.co/sb3\n\nSome examples:\n- Asteroids: https://huggingface.co/sb3/dqn-AsteroidsNoFrameskip-v4\n- Beam Rider: https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4\n- Breakout: https://huggingface.co/sb3/dqn-BreakoutNoFrameskip-v4\n- Road Runner: https://huggingface.co/sb3/dqn-RoadRunnerNoFrameskip-v4\n\nLet's load an agent playing Beam Rider: https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4","metadata":{"id":"fyRKcCYY-dIo"}},{"cell_type":"code","source":"%%html\n<video controls autoplay><source src=\"https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4/resolve/main/replay.mp4\" type=\"video/mp4\"></video>","metadata":{"id":"B-9QVFIROI5Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. We download the model using `rl_zoo3.load_from_hub`, and place it in a new folder that we can call `rl_trained`","metadata":{"id":"7ZQNY_r6NJtC"}},{"cell_type":"code","source":"# Download model and save it into the logs/ folder\n!python -m rl_zoo3.load_from_hub --algo dqn --env BeamRiderNoFrameskip-v4 -orga sb3 -f rl_trained/","metadata":{"id":"OdBNZHy0NGTR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Let's evaluate if for 5000 timesteps","metadata":{"id":"LFt6hmWsNdBo"}},{"cell_type":"code","source":"!python -m rl_zoo3.enjoy --algo dqn --env BeamRiderNoFrameskip-v4 -n 5000  -f rl_trained/ --no-render","metadata":{"id":"aOxs0rNuN0uS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Why not trying to train your own **Deep Q-Learning Agent playing BeamRiderNoFrameskip-v4? üèÜ.**\n\nIf you want to try, check https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4#hyperparameters **in the model card, you have the hyperparameters of the trained agent.**","metadata":{"id":"kxMDuDfPON57"}},{"cell_type":"markdown","source":"But finding hyperparameters can be a daunting task. Fortunately, we'll see in the next Unit, how we can **use Optuna for optimizing the Hyperparameters üî•.**\n","metadata":{"id":"xL_ZtUgpOuY6"}},{"cell_type":"markdown","source":"## Some additional challenges üèÜ\nThe best way to learn **is to try things by your own**!\n\nIn the [Leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard) you will find your agents. Can you get to the top?\n\nHere's a list of environments you can try to train your agent with:\n- BeamRiderNoFrameskip-v4\n- BreakoutNoFrameskip-v4\n- EnduroNoFrameskip-v4\n- PongNoFrameskip-v4\n\nAlso, **if you want to learn to implement Deep Q-Learning by yourself**, you definitely should look at CleanRL implementation: https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/atari-envs.gif\" alt=\"Environments\"/>","metadata":{"id":"-pqaco8W-huW"}},{"cell_type":"markdown","source":"________________________________________________________________________\nCongrats on finishing this chapter!\n\nIf you‚Äôre still feel confused with all these elements...it's totally normal! **This was the same for me and for all people who studied RL.**\n\nTake time to really **grasp the material before continuing and try the additional challenges**. It‚Äôs important to master these elements and having a solid foundations.\n\nIn the next unit, **we‚Äôre going to learn about [Optuna](https://optuna.org/)**. One of the most critical task in Deep Reinforcement Learning is to find a good set of training hyperparameters. And Optuna is a library that helps you to automate the search.\n\n\n","metadata":{"id":"paS-XKo4-kmu"}},{"cell_type":"markdown","source":"\n\n### This is a course built with you üë∑üèø‚Äç‚ôÄÔ∏è\n\nFinally, we want to improve and update the course iteratively with your feedback. If you have some, please fill this form üëâ https://forms.gle/3HgA7bEHwAmmLfwh9\n\nWe're constantly trying to improve our tutorials, so **if you find some issues in this notebook**, please [open an issue on the Github Repo](https://github.com/huggingface/deep-rl-class/issues).","metadata":{"id":"5WRx7tO7-mvC"}},{"cell_type":"markdown","source":"See you on Bonus unit 2! üî•","metadata":{"id":"Kc3udPT-RcXc"}},{"cell_type":"markdown","source":"### Keep Learning, Stay Awesome ü§ó","metadata":{"id":"fS3Xerx0fIMV"}}]}